# Phase 0 : Backend Set Up

Set up includes:

1. Creating basic project structure.
2. Installing dependencies.
3. Setting up Diesel.
4. Initializing Axum.
5. Connecting security middlewares.
6. Testing your server setup.

## Create a project folder and a README for your project

Using cargo new, create a project directory with the name of your project.
```shell
cargo new $project_name
```

Within the root of your new project directory, create a file called `README.md`.
```shell
touch README.md
```

The `README.md` will include the API documentation and the database schema.

GitHub will utilize this file to be displayed on the main page of your repository on GitHub.

Learn more about [GitHub READMEs here][github-readmes].

Create an `images` folder at the root of your project directory.
```shell
mkdir images
```

Later we will create an image of the schema for documenting our structure to other users.

Add the following to your README.md replacing `[title]` with the name of your project:


```markdown
# [title]

## Database Schema Design

![db-schema]

[db-schema]: ./images/schema.png

## API Documentation
```

[github-readmes]: https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes





## `.gitignore`

Create a `.gitignore` file at the root of the project with the following
contents:

```plaintext
.env
```

## Git

Make sure your local machine's Git configuration initializes new Git repositories
with a default branch of `main` by running:

```bash
git config --global init.defaultBranch main
```

Initiate Git in the project folder by running the following command in the
root directory of your project folder:

```bash
git init
```

[Create a public remote git repository in GitHub][new-git-repo] with the same name as your project folder.


**Note**: Make sure the GitHub repo that you create is "Public", NOT "Private".

Connect your remote repository to your local repository by running the following
command in the root directory:

```bash
git remote add origin <github-remote-url>
```

Replace `github-remote-url` with the URL that was generated by
GitHub after creating the public remote GitHub repository.

Make your first commit and push it to the remote repository.

```bash
git add .
git status
```

Confirm that the files to be added include the `README.md` and `.gitignore` files
that you created.

Commit the changes:

```bash
git commit -m 'Initial commit'
```

Push the commit to the GitHub remote repository:

```bash
git push origin main
```

Confirm that you see the `README.md` and `.gitignore` file on GitHub.

After pushing to GitHub, the `README.md` file should now be rendered as the
repository's main page.

## Backend and Frontend Separation

In this project, you will separate the backend Axum code from the frontend
React code.

Inside of the root directory of your project folder, create two folders called
`backend` and `frontend`.

Your file structure should look like this:

```plaintext
.
â”œâ”€â”€ backend/
â”œâ”€â”€ frontend/
â”œâ”€â”€ images/
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Dependencies

In the `Cargo.toml` file and add the following dependencies:

```toml
[dependencies]
pq-sys = "0.6.0"                                                            # Rust binding to the PostgreSQL library
axum = "0.8.1"                                                              # Server
axum-macros = "0.5.0"                                                       # Server macros
diesel = { version = "2.2.8", features = ["postgres", "chrono", "r2d2"] }   # ORM
dotenvy = "0.15.7"                                                          # For getting environment variables

serde = { version = "1.0.219", features = ["derive"] }
serde_json = "1.0.140"

tokio = { version = "1.44.1", features = ["full"] }

cookie = "0.18.1"
csrf = "0.5.0"                                                              # CSRF protection
jsonwebtoken = "9.3.1"                                                      # JWT implementation

tower = "0.4"

tower-http = { version = "0.6.2", features = [                              # provides HTTP-specific middleware and utilities built on top of tower
    "catch-panic",                                                          # Convert panics into responses.
    "cors",                                                                 # CORS middleware
    "set-header",                                                           # Security headers middleware (helmet equivalent)
    "set-status",                                                           # Middleware to override status codes.
    "trace",                                                                # Middleware for HTTP request/response logging
    "validate-request",                                                     # Middleware that validates requests.
] }


tracing = "0.1.41"                                                          # Logging framework
tracing-subscriber = "0.3.19"                                               # Logging implementation

config = "0.13"                                                             # Configuration management with environment support
thiserror = "2.0.12"                                                        # Error handling
chrono = { version = "0.4", features = ["serde"] }


[dev-dependencies]
cargo-watch = "8.5.3"                                                       # Equivalent to nodemon

```

From the root do a cargo run to compile the dependencies:

```shell
cargo run
```

## Create Postgres Database

In terminal log in to psql.

Then run:

```sql
CREATE DATABASE your_database_name
```

## Configuration

In the `backend` folder, create a `.env` to define your environment variables.

Populate the `.env` file based on the example below:

```plaintext
SERVER_PORT=5678
DATABASE_URL=postgres://postgres:postgres@localhost/Â«your_database_name_hereÂ»
DB_PORT=5432
DB_FILE=db/dev.db
JWT_SECRET=Â«generate_strong_secret_hereÂ»
JWT_EXPIRES_IN=604800
SCHEMA=Â«custom_schema_name_hereÂ»
RUST_LOG=debug
```

Assign `DB_PORT` to `5432`, choose a custom schema name in snake case, and generate a strong JWT secret.

> Recommendation to generate a strong secret: <br>
>  - Create a random string using `openssl`. <br>
>  - `openssl` should already be installed in your Ubuntu/MacOS shell. <br>
>  - To generate a random JWT secret run:
> ```shell
>    openssl rand -base64 10
> ```
> - This generates a pseudo randomized string of 10 characters.
> - Copy and paste the generated string to your .env file. <br>
> <br>

Next create a configuration file to read the environment variables and export them.

Add a folder called `config` in your `backend` folder.
```shell
mkdir config
```

Inside the `config` folder, create an `config.rs` file with the following contents:

```rust
use serde::Deserialize;
use std::env::{self, VarError};
use thiserror::Error;

#[derive(Error, Debug)]
pub enum ConfigError {
    #[error("Environment variable error: {0}")]
    EnvVar(#[from] VarError),
    #[error("{0}")]
    Other(String),
}

#[derive(Debug, Deserialize)]
pub struct Config {
    pub database_url: String,
    pub jwt_secret: String,
    pub rust_log: String,
    pub jwt_expires_in: String,
    pub schema: String,
}

impl Config {
    pub fn new() -> Result<Self, ConfigError> {
        Ok(Config {
            database_url: env::var("DATABASE_URL")
                .map_err(|_| ConfigError::Other("DATABASE_URL must be set".to_string()))?,

            jwt_secret: env::var("JWT_SECRET")
                .map_err(|_| ConfigError::Other("JWT_SECRET must be set".to_string()))?,

            rust_log: env::var("RUST_LOG")
                .map_err(|_| ConfigError::Other("RUST_LOG must be set".to_string()))?,

            jwt_expires_in: env::var("JWT_EXPIRES_IN")
                .map_err(|_| ConfigError::Other("JWT_EXPIRES_IN must be set".to_string()))?,

            schema: env::var("SCHEMA")
                .map_err(|_| ConfigError::Other("SCHEMA must be set".to_string()))?,
        })
    }
}
```

Each environment variable will be read and exported as a key from this file.


## Diesel Setup

Initialize Diesel in your project by runing this command in the root:

```shell
diesel setup
```

This command will:
- Create a migrations directory
- Create a diesel.toml file
- Create the database if it doesn't exist


Create your first migration by running this command in the root:

```shell
diesel migration generate your_table_name
```

This creates two files in migrations/[timestamp]_your_table_name/:
- up.sql: Define your table schema
- down.sql: Define how to revert the migration


Edit the up.sql with your table creation SQL. For example:
```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name VARCHAR NOT NULL,
    username VARCHAR NOT NULL,
    email VARCHAR NOT NULL,
    password_hash VARCHAR NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
);
```

Edit the down.sql with your table creation SQL. For example:
```sql
DROP TABLE users;
```


Set up the database connection in a new file src/db.rs:

```rs
use diesel::prelude::*;

pub fn establish_connection(database_url: &str) -> PgConnection {
    PgConnection::establish(database_url)
        .unwrap_or_else(|_| panic!("Error connecting to {}", database_url))
}
```



Run the migration from the root:
```shell
diesel migration run
```

After running the migration, Diesel will:
- Execute your up.sql file
- Create a schema.rs file in your src directory
- Track the migration in a diesel schema migrations table


To verify your migrations, you can run these commands from the root:

- List all migrations and their status
```shell
diesel migration list
```

- Check if any migrations are pending
```shell
diesel migration pending
```

- Run any pending migrations
```shell
diesel migration run
```

- Revert a migration:
```shell
diesel migration revert
```

- Redo a migration:
```shell
diesel migration redo
```

After completing these steps, your project will be set up with Diesel and ready to interact with your database.

The schema.rs file will be automatically generated by Diesel when you run migrations.

You'll need to create your model files to define your database models.

## Models

It is best to create a models directory with an entry file for cleaner import/export. A possible configuration could be:

```
src/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mod.rs          # Re-exports all models
â”‚   â”œâ”€â”€ user.rs         # User model
â”‚   â”œâ”€â”€ post.rs         # Post model
â”‚   â””â”€â”€ ...             # Other model files
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ mod.rs          # Re-exports all models
â”‚   â”œâ”€â”€ config.rs       # Configs
â”‚   â””â”€â”€ ...             # Other config files
â”œâ”€â”€ db.rs
â”œâ”€â”€ schema.rs
â””â”€â”€ main.rs
```

The models/mod.rs file is an entry file for importing/exporting:

```rust
// importing the models
mod user;
mod post;

// re-export models
pub use user::*;
pub use post::*;
```

Then create the user model as follows:

```rust
use diesel::prelude::*;
use serde::{Deserialize, Serialize};
use crate::schema::users;

#[derive(Queryable, Selectable, Deserialize, Serialize)]
#[diesel(table_name = crate::schema::users)]
#[diesel(check_for_backend(diesel::pg::Pg))]
pub struct User {
    pub id: i32,
    pub name: String,
    pub username: String,
    pub email: String,
    pub password_hash: String,
    pub created_at: chrono::NaiveDateTime,
    pub updated_at: chrono::NaiveDateTime,
}

#[derive(Insertable, Deserialize)]
#[diesel(table_name = users)]
pub struct NewUser {
    pub name: String,
    pub username: String,
    pub email: String,
    pub password_hash: String,
}

#[derive(AsChangeset,Deserialize)]
#[diesel(table_name = users)]
pub struct UpdateUser {
    pub name: Option<String>,
    pub username: Option<String>,
    pub email: Option<String>,
    pub password: Option<String>,
}
```

Make sure to add the following to your src/lib.rs or src/main.rs:
```
#[macro_use]
extern crate diesel;

pub mod schema;
pub mod models;
```

## Axum Setup

After you setup Diesel, it's time to start working on getting your Axum
application set up.

### `What Is Axum`

Axum is a web app framework that focuses on modularity.

It does not have its own middleware therefore it uses tower::Service.

Because of this you can share middleware with applications written using hyper or tonic(?).

Axum is compatible to work with tokio as well.



## `main.rs`

The `main.rs` file will be where you initialize your Axum application.

At the top of the file, import the following packages:

```rust
use diesel::prelude::*;
use diesel::r2d2::{self, ConnectionManager, Pool};
use dotenvy::dotenv;
use std::sync::Arc;
use axum::{
    routing::{get, post},
    Router,
    extract::State,
};
use std::net::SocketAddr;

#[macro_use]
extern crate diesel;
pub mod models;
pub mod schema;

mod db;
mod config;

use config::Config;
```

Then, before main, create a struct to represent the state for a web application using a PostgreSQL database connection pool.

```rust
pub struct AppState {
    pub db_pool: Pool<ConnectionManager<PgConnection>>,
}

```

We will also want to creates a type alias for a thread-safe shared reference to AppState using Arc (Atomic Reference Counting).

```rust
type AppStateShare = Arc<AppState>;
```

This provides shared ownership of a value across multiple threads, keeping track of the number of references to the data, and only deallocating the data when the last reference is drop.


### fn main

Before we initialize main we need to add the tokio decorator so we can use main as async:

```rust
#[tokio::main]
async fn main() {
```

Then we need to load environment variables from .env into the program's environment using dotenv() from dotenvy.

We also use .ok() to convert the Result into an Option and ignore any errors that might occur if .env can't be loaded:

```rust
dotenv().ok();
```

Then using ConnectionManager we create a manager with the generic type PgConnection that references the database URL from the config.rs file.

```rust
let manager = ConnectionManager::<PgConnection>::new(&config.database_url);
```

Next we use Pool::builder() to create a connection pool with default settings:

```rust
   let pool = Pool::builder()
        .build(manager)
        .expect("Failed to create pool");
```
This establishes the pool with the databse URL from the manager.

```NOTE: Now that we are using manager and pool we no longer need db.rs and the import mod db;```

Next we again use ARC to create a thread-safe shared state containing the database connection pool:

```rust
let shared_state = Arc::new(AppState {
    db_pool: pool,
});
```

Next we initialize the tracing subscriber for logging in your application:

```rust
tracing_subscriber::fmt::init();
```

 The tracing system provides structured logging capabilities that are more powerful than simple println statements.

 Here is a basic usage example of tracing:

 ```rust
 use tracing::{info, warn, error, debug};

// Initialize the default subscriber
tracing_subscriber::fmt::init();

// Now you can use logging macros
info!("Application started");
debug!("Debug information");
warn!("Warning message");
error!("Error occurred: {}", error_message);
```

This increases the capability of logging for example you can customize the logging format and options:

```rust
use tracing_subscriber::fmt::format::FmtSpan;

// More customized initialization
tracing_subscriber::fmt()
    .with_target(false) // Don't include targets in output
    .with_thread_ids(true) // Include thread IDs
    .with_level(true) // Include log levels
    .with_file(true) // Include file path
    .with_line_number(true) // Include line numbers
    .with_thread_names(true) // Include thread names
    .with_span_events(FmtSpan::FULL) // Log all span events
    .json() // Use JSON format
    .init();
```
The logging levels in order of verbosity:

- ERROR: Error conditions

- WARN: Warning messages

- INFO: General information

- DEBUG: Detailed information for debugging

- TRACE: Very detailed debugging information

You can control the log level using the RUST_LOG environment variable:

```rust
RUST_LOG=debug cargo run
# or
RUST_LOG=info,my_crate=debug cargo run
```

Now in fn main we create a new Axum router and configure ti with routes and shared state:

```rust
let app = Router::new()
    .route("/", get(root))
    .route("/health", get(health_check))
    .with_state(shared_state);
```

This router has temporary handlers "root" and "health_check" for the corresponding routes. Handlers will live in different folders and be imported so as to follow the Single Responsility Principle.

Now we must create the listening address for the server which will be a socket address that includes the IP and port:

```rust
let addr = SocketAddr::from(([127, 0, 0, 1], 5678));
println!("Server running on http://{}", addr);
```

Finally we create a TCP listener and start the Axum web server:

```rust
// Create TCP listener bound to our address
let listener = tokio::net::TcpListener::bind(addr).await.unwrap();

// Start serving the application
axum::serve(listener, app.into_make_service())
    .await
    .unwrap();
}
```

Don't forget the closing bracket to close the main function.

The server should run and listen using the socket it was assigned to:

```rust
cargo run
```

Ignore any warnings for now and open the browser to the socket address:

```
http://127.0.0.1:5678
```
You should see "Hello, World!" in the browser!


## `Middleware`

### `Cookies`

There are a few strategies for handling cookies.

1. functionality built in to Axum

    - The official extension from the Axum team, is minimal and works well for simple setups.

2. cookie Crate

    - For more complex cookies

3. tower-cookies

    - A middleware-based cookie manager for Axum & Tower, with easy read/write access and no manual jar passing.

We'll cover each approach but recommend tower-cookies.
<br>

#### Axum For Cookies

In Axum, cookie handling is built into the framework.

In main.rs modify the axum import with the axum::extract::Cookie extractor and axum::response::AppendHeaders for setting cookies.

You don't need a separate middleware like Express's cookie-parser.

But you will need to create handlers and add them to the routes:

```rust

    // Build our application with routes
    let app = Router::new()
        .route("/", get(root))
        .route("/health", get(health_check))
        .route("/set-cookie", get(set_cookie))
        .route("/read-cookie", get(read_cookie))
        .with_state(shared_state);



// New cookie handlers
async fn set_cookie() -> impl IntoResponse {
    AppendHeaders([
        ("Set-Cookie", "session=abc123; HttpOnly; Path=/")
    ])
}

async fn read_cookie(cookie: Option<Cookie>) -> impl IntoResponse {
    match cookie {
        Some(cookie) => format!("Cookie value: {}", cookie.value()),
        None => "No cookie found".to_string(),
    }
}
```

Here's how your new main.rs should look:

```rust
use diesel::prelude::*;
use diesel::r2d2::{self, ConnectionManager, Pool};
use dotenvy::dotenv;
use std::sync::Arc;

mod db;
mod config;

use config::Config;

use axum::{
    routing::{get, post},
    Router,
    extract::{State, Cookie},
    response::{AppendHeaders, IntoResponse},
};
use std::net::SocketAddr;

#[macro_use]
extern crate diesel;
pub mod models;
pub mod schema;

// Define AppState to hold shared state
pub struct AppState {
    pub db_pool: Pool<ConnectionManager<PgConnection>>,
}

// Create a type alias for convenience
type AppStateShare = Arc<AppState>;

#[tokio::main]
async fn main() {
    // Load .env file
    dotenv().ok();

    // Access environment variables
    let config: Config = Config::new().expect("Failed to load configuration");

    // Set up connection pool
    let manager = ConnectionManager::<PgConnection>::new(&config.database_url);
    let pool = Pool::builder()
        .build(manager)
        .expect("Failed to create pool");

    // Create shared state
    let shared_state = Arc::new(AppState {
        db_pool: pool,
    });

    // Initialize tracing for logging
    tracing_subscriber::fmt::init();

    // Build our application with routes
    let app = Router::new()
        .route("/", get(root))
        .route("/health", get(health_check))
        .route("/set-cookie", get(set_cookie))
        .route("/read-cookie", get(read_cookie))
        .with_state(shared_state);

    // Run the server
    let addr = SocketAddr::from(([127, 0, 0, 1], 5678));
    println!("Server running on http://{}", addr);

    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app.into_make_service())
        .await
        .unwrap();
}

// Example of a handler using state
async fn root(
    State(state): State<AppStateShare>,
    cookie: Option<Cookie>,
) -> impl IntoResponse {
    // You can now access both state and cookies
    "Hello, World!"
}

// Health check endpoint
async fn health_check() -> &'static str {
    "OK"
}

// New cookie handlers
async fn set_cookie() -> impl IntoResponse {
    AppendHeaders([
        ("Set-Cookie", "session=abc123; HttpOnly; Path=/")
    ])
}

async fn read_cookie(cookie: Option<Cookie>) -> impl IntoResponse {
    match cookie {
        Some(cookie) => format!("Cookie value: {}", cookie.value()),
        None => "No cookie found".to_string(),
    }
}

```
<br>

#### cookie crate For Cookies


For more complex cookie operations, you can use the cookie crate (which you already have in your dependencies). Here's an example:

```rust
use cookie::{Cookie as RawCookie, SameSite};

async fn set_complex_cookie() -> impl IntoResponse {
    let cookie = RawCookie::build("session", "value123")
        .path("/")
        .secure(true)
        .http_only(true)
        .same_site(SameSite::Strict)
        .finish();

    AppendHeaders([
        ("Set-Cookie", cookie.to_string())
    ])
}
```
<br>

#### tower-cookies For Cookies

You can also use tower-cookies which provides a more streamlined approach.

First add the latest tower-cookies dependency to the cargo.toml:

```shell
cargo add tower-cookies
```

Create a folder called Middleware and then a file called cookies.rs with this code:

```rust
use tower_cookies::{CookieManagerLayer, Cookies, Cookie};
use axum::{response::IntoResponse, Json};
use serde_json::json;

/// Adds a signed cookie
pub fn set_jwt_cookie(cookies: &Cookies, token: &str) {
    let mut cookie = Cookie::new("jwt", token.to_string());
    cookie.set_path("/");
    cookie.set_http_only(true);
    cookie.set_secure(true);

    cookies.add(cookie);
}

/// Retrieves JWT from cookie
pub fn get_jwt_cookie(cookies: &Cookies) -> Option<String> {
    cookies.get("jwt").map(|c| c.value().to_string())
}

/// Example protected route using the jwt cookie
pub async fn protected_route(cookies: Cookies) -> impl IntoResponse {
    match get_jwt_cookie(&cookies) {
        Some(token) => Json(json!({
            "success": true,
            "token": token
        }))
        .into_response(),

        None => Json(json!({
            "success": false,
            "message": "Unauthorized"
        }))
        .into_response(),
    }
}

/// Expose cookie middleware layer
pub fn cookie_layer() -> CookieManagerLayer {
    CookieManagerLayer::new()
}
```
In the Middleware folder add a mod.rs and add the import/export:

```rust
pub mod cookies;
```

Then in main.rs add the import:

```rust
use middleware::cookies::{cookie_layer, protected_route};
```
Then in main.rs add the handlers to the router:

```rust
    let app: Router = Router::new()
        .route("/", get(root))
        .route("/health", get(health_check))
        .route("/protected", get(protected_route))
        .with_state(shared_state)
        .layer(cookie_layer())
```
<br>

#### Comparing Approaches For Cookies

This last approach is recommended because it manages some cookie operations automatically:

```text
    - No need to pass `CookieJar`around in handlers â€” cookies are injected via extractor (`Cookies`).
    - More convenient and ergonomic for real-world apps (especially with multiple layers).
    - Supports signed and private cookies with `Key`.
    - Inspired by cookies in Express.js and Koa (intuitive for web devs coming from those).
    - More middleware-friendly (cookies persist across all handlers/middleware automatically).
```

Here is a breakdown comparison of the approaches:

```text
    | Use Case                               | Use `tower-cookies` âœ… | Use `axum-extra::CookieJar` âœ…|
    |----------------------------------------|------------------------|-------------------------------|
    | Full app with sessions/auth            | âœ… Yes                 | Maybe                         |
    | Want ergonomic read/write cookies      | âœ… Yes                 | ðŸ‘Ž Manual                     |
    | Only need simple read/set              | ðŸ‘Ž Overkill            | âœ… Yes                        |
    | Stateless APIs, cookie just for flavor | ðŸ‘Ž                     | âœ… Yes                        |
    | Already using Axum extra extractors    | Maybe                  | âœ…                            |
    | Want auto cookie injection             | âœ… Yes                 | ðŸ‘Ž                            |

```
<br>


## `CORS`

In Axum, CORS is handled through the tower-http crate's CorsLayer.

We only allow CORS (Cross-Origin Resource Sharing) in development.

The React frontend will be served from a different server than the Axum server.

CORS isn't needed in production since all of our React and Axum resources will come from the same origin.

To begin we add to the middlware folder a file cors.rs:

```rust
use axum::http::{HeaderName, HeaderValue, Method};
use tower_http::cors::CorsLayer;

pub fn create_cors_layer(environment: &str) -> CorsLayer {
    if environment == "production" {
        CorsLayer::new()
            .allow_origin("https://your-production-domain.com".parse::<HeaderValue>().unwrap())
            .allow_methods([Method::GET, Method::POST, Method::PATCH, Method::DELETE])
            .allow_headers([
                HeaderName::from_static("content-type"),
                HeaderName::from_static("authorization"),
            ])
            .allow_credentials(true)
    } else {
        CorsLayer::new()
            .allow_origin("http://127.0.0.1:5678".parse::<HeaderValue>().unwrap())
            .allow_methods([
                Method::GET,
                Method::POST,
                Method::PATCH,
                Method::DELETE,
                Method::OPTIONS,
            ])
            .allow_headers([
                HeaderName::from_static("content-type"),
                HeaderName::from_static("authorization"),
                HeaderName::from_static("accept"),
            ])
            .allow_credentials(true)
    }
}
```
Next we update the mod.rs in the Middleware folder with import/export:

```rust
pub mod cors;
```
Then add the import of the cors middleware and CorsLayer to main.rs:
```rust
use tower_http::cors::CorsLayer;

mod middleware;
use middleware::cors::create_cors_layer;
```
Finally add the layer to the router after shared state but before cookies:
```rust
.layer(cors)
```


We can test our root and health routes with fetches in the browser:

```javascript
// Test GET request to root
fetch('http://localhost:5678/', {
  method: 'GET',
  credentials: 'include', // necessary for CORS with credentials
  headers: {
    'Content-Type': 'application/json'
  }
})
.then(response => response.text())
.then(data => console.log(data))
.catch(error => console.error('Error:', error));

// Test health check endpoint
fetch('http://localhost:5678/health', {
  method: 'GET',
  credentials: 'include',
  headers: {
    'Content-Type': 'application/json'
  }
})
.then(response => response.text())
.then(data => console.log(data))
.catch(error => console.error('Error:', error));
```

We can also test this from the command line with curl:

```shell
# Test GET request to root
curl -X GET http://localhost:5678/ \
  -H "Content-Type: application/json" \
  -H "Origin: http://localhost:5173"

# Test health check endpoint
curl -X GET http://localhost:5678/health \
  -H "Content-Type: application/json" \
  -H "Origin: http://localhost:5173"

# Test CORS preflight request
curl -X OPTIONS http://localhost:5678/ \
  -H "Origin: http://localhost:5173" \
  -H "Access-Control-Request-Method: GET" \
  -H "Access-Control-Request-Headers: content-type" \
  -v
```


## `Security Headers`


Helmet is specifically for Node.js/Express applications.

Therefore we use Axum's built-in middleware capabilities or Tower middleware to implement similar security headers.

In Middleware folder create a security_headers.rs:

```rust
use axum::{
    middleware::Next,
    response::Response,
    http::{Request, HeaderValue, header, HeaderName},
    body::Body,
};

pub async fn security_headers(
    request: Request<Body>,
    next: Next,
) -> Response {
    let mut response = next.run(request).await;
    let headers = response.headers_mut();

    // Content Security Policy
    headers.insert(
        header::CONTENT_SECURITY_POLICY,
        HeaderValue::from_static("default-src 'self'; script-src 'self'")
    );

    // XSS Protection
    headers.insert(
        header::X_XSS_PROTECTION,
        HeaderValue::from_static("1; mode=block")
    );

    // X-Frame-Options
    headers.insert(
        header::X_FRAME_OPTIONS,
        HeaderValue::from_static("DENY")
    );

    // X-Content-Type-Options
    headers.insert(
        header::X_CONTENT_TYPE_OPTIONS,
        HeaderValue::from_static("nosniff")
    );

    // Referrer Policy
    headers.insert(
        header::REFERRER_POLICY,
        HeaderValue::from_static("strict-origin-when-cross-origin")
    );

    // Strict-Transport-Security (HSTS)
    headers.insert(
        header::STRICT_TRANSPORT_SECURITY,
        HeaderValue::from_static("max-age=31536000; includeSubDomains")
    );

    // Permissions Policy
    headers.insert(
        HeaderName::from_static("permissions-policy"),
        HeaderValue::from_static(
            "accelerometer=(), camera=(), geolocation=(), gyroscope=(), magnetometer=(), microphone=(), payment=(), usb=()"
        )
    );

    response
}
```

Update the mod.rs in the Middlware folder to include the import/export:

```rust
pub mod security_headers;
```

Add the import to main.rs:
```rust
use middleware::security_headers::security_headers;
```

Finally add the security_headers as a layer on the router in main.rs:

```rust
.layer(from_fn(security_headers));
```

<br>



## `CSURF`

To add csurf protection we need to add the rand crate to cargo toml:

```toml
rand = 0.8
```

Then create in Middleware a file csrf.rs:

```rust
use axum::{
    middleware::Next,
    response::Response,
    http::{Request, StatusCode, HeaderValue, Method},
    body::Body,
};

/// CSRF middleware for protecting against Cross-Site Request Forgery attacks
pub async fn csrf_middleware(
    request: Request<Body>,
    next: Next,
) -> Result<Response, StatusCode> {
    // Only verify CSRF token for unsafe methods
    if is_unsafe_method(request.method()) {
        // Check for CSRF token in headers
        let token = request
            .headers()
            .get("X-CSRF-Token")
            .and_then(|t| t.to_str().ok())
            .ok_or(StatusCode::FORBIDDEN)?;

        // In a real implementation, verify the token against a stored value
        if token.is_empty() {
            return Err(StatusCode::FORBIDDEN);
        }
    }

    // Process the request
    let mut response = next.run(request).await;

    // Generate and add new CSRF token to response
    let new_token = generate_token();
    if let Ok(header_value) = HeaderValue::from_str(&new_token) {
        response.headers_mut().insert("X-CSRF-Token", header_value);
    }

    Ok(response)
}

/// Helper function to check if a method is unsafe (requires CSRF protection)
fn is_unsafe_method(method: &Method) -> bool {
    matches!(
        *method,
        Method::POST | Method::PUT | Method::DELETE | Method::PATCH
    )
}

/// Generate a new CSRF token
fn generate_token() -> String {
    use rand::{thread_rng, Rng};
    const CHARSET: &[u8] = b"ABCDEFGHIJKLMNOPQRSTUVWXYZ\
                            abcdefghijklmnopqrstuvwxyz\
                            0123456789";
    const TOKEN_LEN: usize = 32;

    let mut rng = thread_rng();

    let token: String = (0..TOKEN_LEN)
        .map(|_| {
            let idx = rng.gen_range(0..CHARSET.len());
            CHARSET[idx] as char
        })
        .collect();

    token
}
```

Update the Middleware mod.rs with the import/export:

```rust
pub mod csrf
```

Import the csrf in main.rs:

```rust
use middleware::csrf::csrf_middleware;
```

Add the csrf to the router before the security headers:

```rust
.layer(from_fn(csrf_middleware))
```
<br>



## `Test Routes JWT`

We can make some test routes to check the set and get functions.

In cookies.rs add the following:

```rust
// Test route to set JWT cookie
pub async fn test_set_jwt(cookies: Cookies) -> impl IntoResponse {
    // Create a sample JWT token - in production this would be properly generated
    let test_token = "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX";

    // Set the JWT cookie
    set_jwt_cookie(&cookies, test_token);

    // Return a response we can see in the browser
    Json(json!({
        "message": "JWT cookie is set",
        "status": "success",
        "test_token": test_token
    }))
}



// Test route to verify JWT cookie
pub async fn test_get_jwt(cookies: Cookies) -> impl IntoResponse {
    match get_jwt_cookie(&cookies) {
        Some(token) => Json(json!({
            "message": "JWT cookie found",
            "token": token
        })),
        None => Json(json!({
            "message": "No JWT cookie found",
            "token": null
        }))
    }
}
```

Notice that these handlers are passing cookies: Cookies argument.

When this is passed in the handler it appears to trigger the set_jwt_token function.

Now in main.rs add the imports for these handlers:

```rust
use middleware::cookies::{cookie_layer, protected_route, test_set_jwt, test_get_jwt};
```

Finally add the routes to the router after the root and health routes:

```rust
        .route("/", get(root))
        .route("/health", get(health_check))
        .route("/test/set-jwt", get(test_set_jwt))
        .route("/test/get-jwt", get(test_get_jwt))
```

Now run the app and navigate to the endpoint /test/set-jwt then /test/get-jwt.

You should get a success message with the false test jwt for both.
<br>


## `Seeders`

Before we make routes we should make seeders to have data to test the routes.

In src run the following commands:

```shell
mkdir db db/seeders
touch db/mod.rs
cd db/seeders
touch mod.rs users.rs database.rs
```

The file structure should be:

```text
src/
â”œâ”€â”€ main.rs
â”œâ”€â”€ bin/
â”‚   â””â”€â”€ seed.rs
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ mod.rs             # exports seeders module
â”‚   â””â”€â”€ seeders/
â”‚       â”œâ”€â”€ mod.rs         # exports database and users modules
â”‚       â”œâ”€â”€ database.rs    # contains DatabaseSeeder struct
â”‚       â””â”€â”€ users.rs       # contains seed_users function
â”œâ”€â”€ models/
â””â”€â”€ schema.rs

```

Add this to the db/mod.rs:

```rust
pub mod seeders;

```

Add this to the db/seeders/mod.rs:

```rust
mod users;
mod database;

pub use database::DatabaseSeeder;
pub use users::*;
```

We will use bcrypt for hashing and salting so add it in cargo.toml:

```toml
[dependencies]
bcrypt = "0.15"  # Or whatever the latest version is
```

Add this to the db/seeders/users.rs:

```rust
// src/db/seeders/users.rs
use diesel::prelude::*;
use crate::models::user::NewUser;
use crate::schema::users;
use bcrypt::{hash, DEFAULT_COST}; // You'll need the bcrypt crate for password hashing

pub fn seed_users(conn: &mut PgConnection) -> QueryResult<()> {
    // First clear the table to avoid duplicates
    diesel::delete(users::table).execute(conn)?;

    let users = vec![
        NewUser {
            name: "John Doe".to_string(),
            username: "johndoe".to_string(),
            email: "john@example.com".to_string(),
            password_hash: hash("password123", DEFAULT_COST).unwrap(),
        },
        NewUser {
            name: "Jane Smith".to_string(),
            username: "janesmith".to_string(),
            email: "jane@example.com".to_string(),
            password_hash: hash("password123", DEFAULT_COST).unwrap(),
        },
    ];

    diesel::insert_into(users::table)
        .values(&users)
        .execute(conn)?;

    Ok(())
}
```

Add this to the db/seeders/database.rs:

```rust
// src/db/seeders/database.rs
use diesel::prelude::*;
use super::users::seed_users;

pub struct DatabaseSeeder {
    conn: &'static mut PgConnection,
}

impl DatabaseSeeder {
    pub fn new(conn: &'static mut PgConnection) -> Self {
        DatabaseSeeder { conn }
    }

    pub fn run(&mut self) -> QueryResult<()> {
        seed_users(&mut self.conn)?;
        // Add more seed calls as needed
        Ok(())
    }
}
```

Next we need a binary file to run the seeders.

In src run the following commands:

```shell
mkdir bin
cd bin
touch bin/seed.rs
```

Add this to the bin/seed.rs:

```rust
// src/bin/seed.rs
use diesel::prelude::*;
use diesel::pg::PgConnection;
use dotenv::dotenv;
use std::env;
// Update this path to match your project structure
use your_project_name::db::seeders::DatabaseSeeder;

fn main() {
    dotenv().ok();
    let database_url = env::var("DATABASE_URL")
        .expect("DATABASE_URL must be set");

    let mut conn = PgConnection::establish(&database_url)
        .expect("Error connecting to database");

    let conn_static = Box::leak(Box::new(conn));

    let mut seeder = DatabaseSeeder::new(conn_static);

    match seeder.run() {
        Ok(_) => println!("Database seeded successfully!"),
        Err(e) => eprintln!("Error seeding database: {}", e),
    }
}
```

Add information for the bin and seeders to cargo.toml:

```toml
[[bin]]
name = "seed"
path = "src/bin/seed.rs"
```

Add imports to include the necessary information in main.rs:

```rust
#[macro_use]
extern crate diesel;
pub mod models;
pub mod schema;
pub mod db;
```

Be sure the .env has the correct information set:

```shell
DATABASE_URL=postgres://username:password@localhost/database_name
```

Finally run the seeder in the shell:

```shell
cargo run --bin seed
```

You will experience issues because your project name has dashes instead of underscores.

In which case you can use the seeder logic in main.rs instead of in a separate bin.

Delete the bin directory and the [bin] information added to cargo.toml.

Adjust main.rs with the following:

```rust
// src/main.rs
#[macro_use]
extern crate diesel;
pub mod models;
pub mod schema;
pub mod db;

pub fn seed_database() -> Result<(), Box<dyn std::error::Error>> {
    use diesel::prelude::*;
    use dotenv::dotenv;
    use std::env;
    use crate::db::seeders::DatabaseSeeder;

    dotenv().ok();
    let database_url = env::var("DATABASE_URL")
        .expect("DATABASE_URL must be set");

    let mut conn = PgConnection::establish(&database_url)
        .expect("Error connecting to database");

    let conn_static = Box::leak(Box::new(conn));

    let mut seeder = DatabaseSeeder::new(conn_static);

    match seeder.run() {
        Ok(_) => println!("Database seeded successfully!"),
        Err(e) => {
            eprintln!("Error seeding database: {}", e);
            return Err(Box::new(e));
        }
    }

    Ok(())
}

fn main() {
    // Your regular main application code here

    // To run the seeder, you can either:
    // 1. Call it directly:
    // seed_database().unwrap();

    // 2. Or use a command-line argument to determine when to seed:
    if std::env::args().any(|arg| arg == "--seed") {
        seed_database().unwrap();
    }
}
```

Now you can run the seeder by uncommenting the direct call in main or in the shell:

```shell
cargo run -- --seed
```



<br>

## `JSON`

In Axum, JSON handling is built-in through extractors.

Add Json to the Axum import in main.rs:

```rust
use axum::{
    extract::Json,
    response::Json as JsonResponse,
};
```

You will use the Json extractor directly in your route handlers.

Here's an example how to handle JSON:

```rust
// Handler that receives JSON
async fn create_user(
    Json(payload): Json<User>
) -> impl IntoResponse {
    // payload is now a User struct
    println!("Received user: {} {}", payload.name, payload.email);

    // Return JSON response
    Json(User {
        name: payload.name,
        email: payload.email,
    })
}

// In your router setup:
let app = Router::new()
    .route("/users", post(create_user));

// Shell
curl -X POST -H "Content-Type: application/json" -d '{"name":"John","email":"john@example.com"}' http://localhost:5678/users

```
<br>




### Routes

Create a folder called `routes` in your `src` folder. All your routes will
live in this folder.

Create a `mod.rs` file in the `routes` folder for imports/exports.

### users

Create a users.rs file in the 'routes' folder.

This will contain routes for users and the necessary handlers:

```rust
use axum::{
    extract::State,
    response::Json,
    http::StatusCode,
    routing::get,
    Router,
};
use diesel::prelude::*;
use std::sync::Arc;
use crate::{
    models::User,
    schema::users,
    AppState,
};

// Error response struct
#[derive(serde::Serialize)]
struct ErrorResponse {
    message: String,
}

// Router setup function
pub fn user_routes() -> Router<Arc<AppState>> {
    Router::new()
        .route("/users", get(get_users))
}

// Handler implementation
pub async fn get_users(
    State(state): State<Arc<AppState>>
) -> Result<Json<Vec<User>>, (StatusCode, Json<ErrorResponse>)> {
    // Get a connection from the pool (no await needed for r2d2)
    let mut conn = state.db_pool.get()
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(ErrorResponse {
                    message: format!("Database connection error: {}", e)
                })
            )
        })?;

    // Execute the query (directly, no interact needed)
    let users_result = users::table
        .select(User::as_select())
        .load(&mut *conn)
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(ErrorResponse {
                    message: format!("Database error: {}", e)
                })
            )
        });

    match users_result {
        Ok(users) => Ok(Json(users)),
        Err(e) => Err(e)
    }
}


// You can add more handlers here:
// async fn get_user() {...}
// async fn create_user() {...}
// async fn update_user() {...}
// async fn delete_user() {...}
```

Update the mod.rs in Routes to handle the imports/exports:

```rust
mod users;
pub use users::*;
```

Import the user routes and handlers to main.rs:

```rust
mod routes;
use routes::{user_routes};
```

Finally, add the user routes to the router with a .merge as the first route:

```rust
.merge(user_routes())
```


<br>
======================================================================================================================
<br>

### UNCHARTED

In this file, create an Axum router, create a test route, and export the router at the bottom of the
file.

```js
// backend/routes/index.js
const Axum = require('Axum');
const router = Axum.Router();

router.get('/hello/world', function(req, res) {
  res.cookie('XSRF-TOKEN', req.csrfToken());
  res.send('Hello World!');
});

module.exports = router;
```

In this test route, you are setting a cookie on the response with the name of
`XSRF-TOKEN` to the value of the `req.csrfToken` method's return. Then, you are
sending the text, `Hello World!` as the response's body.

Add the routes to the Axum application by importing with the other imports
in `backend/app.js` and connecting the exported router to `app` after all the
middlewares.

```js
// backend/app.js
const routes = require('./routes');

// ...

app.use(routes); // Connect all the routes
```

Finally, at the bottom of the `app.js` file, export `app`.

```js
// backend/app.js
// ...

module.exports = app;
```

After setting up the Axum application, it's time to create the server.









### `bin/www`

Conventionally, the `bin/www` file in an Axum server is the entry file or the
starting point to start the Axum server.

The intention of the `./bin/www` file is for it to be an executable
script, meaning that you could start the application by simply entering the file
name in the terminal as a command:

```sh
bin/www
```

Create a folder in `backend` called `bin`. Inside of it, add a file called
`www` with the following contents:

```js
#!/usr/bin/env node
// backend/bin/www

// Import environment variables
require('dotenv').config();

const { port } = require('../config');

const app = require('../app');
const db = require('../db/models');

// Check the database connection before starting the app
db.Diesel
  .authenticate()
  .then(() => {
    console.log('Database connection success! Diesel is ready to use...');

    // Start listening for connections
    app.listen(port, () => console.log(`Listening on port ${port}...`));
  })
  .catch((err) => {
    console.log('Database connection failure.');
    console.error(err);
  });
```

Here, you will be starting your Axum application to listen for server
requests only after authenticating your database connection.

## Test the Server

At this point, your database, Axum application, and server are all set up and
ready to be tested!

In your `package.json`, add the following scripts:

```json
  "scripts": {
    "Diesel": "Diesel",
    "Diesel-cli": "Diesel-cli",
    "start": "per-env",
    "start:development": "nodemon ./bin/www",
    "start:production": "node ./bin/www",
    "build": "node psql-setup-script.js"
  }
```

`npm start` will run the `/bin/www` in `nodemon` when started in the development
environment with the environment variables in the `.env` file loaded, or in
`node` when started in production.

Now, it's time to finally test your entire set up!

Run `npm start` in the `backend` folder to start your server on the port defined
in the `.env` file, which should be `8000`.

Navigate to the test route at [http://localhost:8000/hello/world]. You should
see the text `Hello World!`. Take a look at your cookies in the `Application`
tab of your Chrome DevTools Inspector. Delete all the cookies to make sure there
are no lingering cookies from other projects, then refresh the page. You should
still see the text `Hello World!` on the page as well as two cookies, one called
`_csrf` and the other called `XSRF-TOKEN` in your DevTools.

If you don't see this, then check your backend server logs in the terminal
where you ran `npm start`. Then check your routes.

If there is a database connection error, make sure you set up the correct
username and password defined in the `.env` file.

When you're finished testing, commit! Now is a good time to commit because you
have working code.

## CSRF Token access for development

You can now remove the `GET /hello/world` test route.

Add a route, `GET /api/csrf/restore` to allow any developer to re-set the CSRF
token cookie `XSRF-TOKEN`.

In this route, you are setting a cookie on the response with the
name of `XSRF-TOKEN` to the value of the `req.csrfToken` method's return. Then,
send the token as the response for easy retrieval.

Add this route to the `backend/routes/index.js` file.

```js
// backend/routes/index.js
// ...
// Add a XSRF-TOKEN cookie
router.get("/api/csrf/restore", (req, res) => {
  const csrfToken = req.csrfToken();
  res.cookie("XSRF-TOKEN", csrfToken);
  res.status(200).json({
    'XSRF-Token': csrfToken
  });
});
// ...
```

This route should not be available in production, but it will not be exclusive
to the production application until you implement the frontend of the
application later. So for now, it will remain available to both the development
and production environments.

## Commit your code

Now is a good time to commit and push your code to GitHub!

Here's a recommendation for what to write as your commit message:
"Initialize Axum and Diesel with CSRF protection"

[new-git-repo]: https://github.com/new
[helmet on the `npm` registry]: https://www.npmjs.com/package/helmet
[Axum error-handling middleware]: https://Axumjs.com/en/guide/using-middleware.html#middleware.error-handling
[model-level validations]: https://Diesel.org/master/manual/validations-and-constraints.html
[model scoping]: https://Diesel.org/master/manual/scopes.html
[Content Security Policy]: https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP
[Cross-Site Scripting]: https://developer.mozilla.org/en-US/docs/Glossary/Cross-site_scripting
[crossOriginResourcePolicy]: https://www.npmjs.com/package/helmet
[http://localhost:8000/hello/world]: http://localhost:8000/hello/world
[http://localhost:8000/not-found]: http://localhost:8000/not-found
[http://localhost:8000/api/set-token-cookie]: http://localhost:8000/api/set-token-cookie
[http://localhost:8000/api/restore-user]: http://localhost:8000/api/restore-user
[http://localhost:8000/api/require-auth]: http://localhost:8000/api/require-auth
[http://localhost:8000/api/session]: http://localhost:8000/api/session
[http://localhost:8000/api/csrf/restore]: http://localhost:8000/api/csrf/restore
